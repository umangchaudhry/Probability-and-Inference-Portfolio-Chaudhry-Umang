---
title: 'Blog Post - Simulation Study: CLT'
output:
  html_document:
    df_print: paged
---

```{r load_libraries}
require(magrittr)
library(sn)
```


# The Central Limit Theorem

The central limit theorem is an important computational short-cut for
generating and making inference from the sampling distribution of the
mean. You’ll recall that the central limit theorem short-cut relies on a
number of conditions, specifically:

1.  Independent observations
2.  Identically distributed observations
3.  Mean and variance exist
4.  Sample size large enough for convergence

# Setup

In this simulation study, we are going to compare the sampling
distribution of the mean generated by simulation to the sampling
distribution implied by the central limit theorem. We will compare the
distributions graphically in QQ-plots.

This will be a 4 × 4 factorial experiment. The first factor will be the
sample size, with N = 5, 10, 20, and 40. The second factor will be the
degree of skewness in the underlying distribution. The underlying
distribution will be the Skew-Normal distribution. The Skew-Normal
distribution has three parameters: location, scale, and slant. When the
slant parameter is 0, the distribution reverts to the normal
distribution. As the slant parameter increases, the distribution becomes
increasingly skewed. In this simulation, slant will be set to 0, 2, 10,
100. Location and scale will be set to 0 and 1, respectively, for all simulation
settings.

To generate the simulated data, we will use the `rsn` function in the `sn` package.

The output of each combination of factors will be a QQ-plot. In this study, we will generate a
sampling distribution of 5000 draws from both the CLT approximation and
the simulation approximation. When analyzing data, the parameters for
the mean and variance (in the case of the CLT shortcut) or the
parameters for the distribution (in the case of MLE, MM, etc) are
replaced with sample estimates. (This is often called the plug-in
approach.) For the purposes of this simulation, we treat the mean and
variance as known values and use the actual population parameters and
the population mean and variance instead of sample estimates.

## Parameter List 

As seen in previous blog posts, we will again be using a list of parameters to pass to the functions we create to generate the sample simulated distributions and sample CLT distributions. The list contains the size, N, slant, R, to indicate the number of draws while generating the sample distribution, the location and the scale parameters for the rsn() function that we will be using to generate the distributions.

```{r parameters_list}
# Parameters list
parameters <-
  list(
    N = 5,
    slant = 10,
    R = 5000,
    location = 0,
    scale = 1
  )
```

Now, we will write the generate_data function, that will take in the list of parameters we created and return the sample simulated and sample CLT distributions. To generate the sample simulated distribution, we use the rsn() function with the vales for n as N*R, as we are creating an array to generate the mean of this distribution to get a more accurate result. We also set slant to alpha, the location as xi, and the scale as omega in the parameters of the rsn() function. Next, to generate the CLT distribution, we create a variable sigma that is the slant/sqrt(1 + (slant)^2), the population mean which is calculated as sqrt(2 / pi) times sigma, the population variance. We use the rnorm function to generate the distribution and then multiply that with (sqrt(pop_variance) / sqrt(N)) + pop_mean. 

```{r generate_data}
generate_data <- function(parameter) {
  dist <-
    array(
      rsn(
        n = parameter$R * parameter$N,
        alpha = parameter$slant,
        xi = parameter$location,
        omega = parameter$scale
      ),
      dim = c(parameter$R, parameter$N)
    )
  parameter$sample_dist_sim <- apply(dist, 1, mean)
  sigma <- parameter$slant / sqrt(1 + (parameter$slant ^ 2))
  pop_mean <- sqrt(2 / pi) * sigma
  pop_variance <- (1 - (2 * (sigma ^ 2) / 3.14))
  Z <- rnorm(parameter$R)
  parameter$sample_dist_clt <-
    Z * (sqrt(pop_variance) / sqrt(parameter$N)) + pop_mean
  return(parameter)
}
```

To plot the distribution, with all the settings we want to test for, we use expand.grid to put all the simulation parameters in a table. We will then use this table to reference the values for N and Slant within a for-loop, that runs 16 times (once for each N-Slant combination), and use the qqplot function each time using the values returned by the generate_data function given the parameters each time through the loop. We use the abline function to plot the x=y line to help understand the variation in the results between the simulated and clt distributions. The par(mfrow) function will plot all of these qqplots in one larger image together to help making comparisons easier. 

```{r plot_distributions}
change_par <-
  expand.grid(
    N = c(5, 10, 20, 40),
    slant = c(0, 2, 10, 100),
    stringsAsFactors = FALSE,
    KEEP.OUT.ATTRS = FALSE
  )

par(mfrow = c(4, 4))
for (i in 1:16) {
  parameters <-
    list(
      N = change_par[i, 1],
      slant = change_par[i, 2],
      R = 5000,
      location = 0,
      scale = 1
    )
  a <- generate_data(parameters)
  qqplot(a$sample_dist_sim, a$sample_dist_clt, asp = 1, main = paste0("N = ", a$N, ", Slant = ", a$slant ), xlab = "Sample Simulated Distribution", ylab = "Sample CLT Distribution")
  abline(0, 1)
}
```

As can be seen from the graphs above, as N increases, the variability between the CLT and simulated distributions decreases and the simulated data becomes more accurate. 
---
title: "Blog Post - Monte Carlo Simulation"
output: html_document
---

```{r setup, include=FALSE}

knitr::knit_hooks$set(inline = function(x) { knitr:::format_sci(x, 'md')})
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

# This section loads necessary R libraries and sources scripts that define 
# useful functions format_md.
# setup chunk copied from an earlier project of mine, and has some extra libraries. 

library(pacman)
library(viridis)
options(tigris_use_cache = TRUE)
p_load(tidyverse, httr, rio, geojson, tigris, mapview, tidycensus, geojsonio, jsonlite, stringr, sf, broom)

```

## Introduction

Monte Carlo methods or experiments are a class of computational algorithms that are based on repeated random sampling to obtain numerical results. The simulations use randomness to solve mathematical problems. However the main issue with this experiment design is that it generates approximate answers. There is some degree of error in the answers generated by the Monte Carlo simulation. Generally, if the number of simulations and replicates increases, the calculated error decreases. In this project, I will explore the relationship between the number of replicates and the calculated error. Monte Carlo approaches to simulation are useful in a variety of fields, and it is important to establish that the efficiency and accuracy of these simulation lies on the principle that increasing the number of replicates, or the number of times the simulation is repeated is inversely proportional to the error generated by the simulation. 

In this project, we will perform a 14X5 factorial experiment simulation that estimates the error for each combination of replicate number (2^2^, 2^3^, …, 2^15^) and probability (0.01, 0.05, 0.10, 0.25, 0.50). Let p̂ denote the probability estimated from simulation, and let p denote the true underlying probability. Calculate error as

absolute error = |p̂−p|

and

relative error = |p̂−p|/p.

For this project, we will be running a binomial distribution and generate the absolute error for each simulation, running a set of different probabilities and number of replicates as explained above. 

## Programming a single run

First, let's examine how a single simulation of this binomial distribution would work. We can first set the number of Replicates, sR, to 500, and the probability of interest, sp, to 0.3. Running a binomial distribution using these two parameters will give us the total number of successes in R draws. 

```{r single_run}
sR <- 500 #replicates
sp <- .3 #probability of interest
rbinom(1, sR, sp) #Gives total number of success in R draws. 
sp_hat <- rbinom(1,sR,sp) / sR 
sabs_error <- abs(sp - sp_hat) # = 0.028 #(absolute error for that replicate)
sabs_error
srel_error <- sabs_error/sp #= 0.09333333
srel_error
```

Running this single run of the simulation creates an array, or list of 1s and 0s which we can use to estimate our p_hat, absolute and relative errors. The values output here are the relative and absolute errors for that particular replicate. 

## Simulation

Now, we can create a simulation where we test simulation error for different number of replicates and probabilities, using the same binomial distribution setup. Using that information we can explore the relationship between the number of simulation replicates and simulation error. 

```{r simulation}

R <- NA #initialize R to NA. 
for (a in seq_along(1:15)) { #Set R to 14 different replicates in a vector
  R[a] <- 2^(a+1)
}
#R <- 2^(seq_along(1:15)) #Alternate way to initialize R

p <- c(0.01 , 0.05, 0.10, 0.25, 0.50) #Create a vector of probabilities being tested 

#p_hat <- matrix(NA, length(R), length(p))
abs_error <- rel_error <- matrix(NA, length(R), length(p)) #Create a vector for absolute and relative error of dimention R X P to store values. 

for (i in 1:length(p)) { #Run a simulation with all different combinations of R and p. 
  for (j in 1:length(R)) {
    #p_hat[j,i] <- rbinom(1,R[j],p[i])/R[j] #Creating a separate matrix for p_hat not required.
    #Input results of calculations of absolute error and relative error into the correct index in the matrix.
    abs_error[j,i] <- mean(abs(p[i]-(rbinom(100000,R[j],p[i])/R[j]))) 
    rel_error[j,i] <- abs_error[j,i]/p[i]
  }
}

abs_error
rel_error

#hist(abs_error[1,]) 
#abline(v = mean(abs_error), lwd = 3, col = "blue")
```

First, vectors containing the number of replicates and probabilities being tested are created. In the simulation, we create a for loop that runs for the length of the vector containing the number of replicates. Within this for loop we create another nested for loop, running for the length of the vector containing the probabilities best tested. Absolute error is calcutated using the built in rbinom function, running 100,000 times, which outputs a matrix containing the absolute error per combination of p and R. The same is done to calculate relative error. 

## Plots

Now, we can plot the results of absolute and relative error and observe the relationship between the absolute error and the number of replicates in the binomial distribution. On the Y-axis, the absolute error is being plotted and the X-axis is the number of replicates. The different colors represent the different probabilities being tested for. 

``` {r plotting}
plot(1:15, abs_error[,5],axes=FALSE,type="o",col="orange",xlab="N (log2 scale)", ylab= "Absolute Error", pch = 16, lwd = 2)
axis(1,1:15,R)
axis(2)
box()
lines(1:15, abs_error[,4], col= "purple",type="o", pch = 16, lwd = 2)
lines(1:15, abs_error[,3], col= "green",type="o", pch = 16, lwd = 2)
lines(1:15, abs_error[,2], col= "blue",type="o", pch = 16, lwd = 2)
lines(1:15,abs_error[,1],col= "red",type="o", pch = 16, lwd = 2)

plot(1:15, rel_error[,5],axes=FALSE, type="o",col="orange",xlab="N (log2 scale)", ylab= "Relative Error", ylim = c(0,2), pch = 16, lwd = 2)
axis(1,1:15,R)
axis(2)
box()
lines(1:15, rel_error[,4], col= "purple",type="o", pch = 16, lwd = 2)
lines(1:15, rel_error[,3], col= "green",type="o", pch = 16, lwd = 2)
lines(1:15, rel_error[,2], col= "blue",type="o", pch = 16, lwd = 2)
lines(1:15, rel_error[,1],col= "red",type="o", pch = 16, lwd = 2)

```

Generally, it can be seen that as the number of replicates increases, both the relative and absolute errors decrease to 0. This demonstrates that for Monte Carlo simulations, degree of error gets smaller as the number of simulation replicates increases.

``` {r notes, include=FALSE}
#empty plot and then use lines()

#p_hat <- rbinom(1,R,p) / R 
#abs_error <- abs(p - p_hat) #= 0.028 #(absolute error for that replicate)
#abs_error
#rel_error <- abs_error/p #= 0.09333333
#rel_error
#What if we want to calculate the mean of the errors over lots of simulations

#USE a for loop 
#abs_error <- rel_error <- rep(NA, 100) #using pre-allocation, more computationally efficient
#for (i in seq_along(abs_error)) { #seq_along because don’t want to have to code the length of the simulation multiple times
#p_hat <- rbinom(1,R,p)/R
#abs_error[i] <- abs(p-p_hat) #looped function
#rel_error[i] <- abs_error[i]/p
#}

#hist(abs_error, breaks = 100)
#abline(v = mean (abs_error), lwd = 3, col = "blue") #add reference line

#Also have a line for the 95th percentile/quantile - worst case scenario for your error - more helpful in understanding the errors of your simulation

#Min max loss/ minimizing the min max - while making decisions of what algorithm to use, we look at mean performance. Sometimes we are more interested in the worst case scenario. Minimization of the maximum possible loss. 

#ALTERNATIVE WAY

#p_hat <- rbinom(100000, R, p) / R #100,000 binomial Rs of size R with probability P
#creates all the P_hats with the for loop in one array
#Abs_error <- abs(p-p_hat) #Vectorized function
#Rel_error <- abs_error/p

#hist (abs_error, breaks = 100) #same histogram as before 
```

